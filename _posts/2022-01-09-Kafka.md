# Kafka

## 中间件的作用

**异步 解隅 流量削峰**

[https://www.cnblogs.com/armyfai/p/13595055.html?ivk_sa=1024320u](https://www.cnblogs.com/armyfai/p/13595055.html?ivk_sa=1024320u)

## 中间件的应用场景

**书内容向推荐系统同步书籍增删改信息**
**新书大数据推送新书信息**
**书籍在某个栏目上的曝光等埋点数据同步**
**图片，评论风控先发后审**
**积分商城，热门商品定时秒杀**

## kafka 的定义

**官方文档的定义是一个分布式流平台**

**发布和订阅记录流，消息队列**

**以容错持久的方式存储记录流**

**处理记录流**

## Kafka 设计

**kafka cluster**

**broker**

**topic**

**parttiton**

**producer**

**comsumer**

**consumer group**

## kafka 多副本机制

**leader 副本 follower 副本**

**Kafka producer 有三种 ack 机制 初始化 producer 时在 config 中进行配置；**

**ack 等于 0：意味着 producer 不等待 broker 同步完成的确认，继续发送下一条(批)信息**

**提供了最低的延迟。但是最弱的持久性，当服务器发生故障时，就很可能发生数据丢失。例如 leader 已经死亡，producer 不知情，还会继续发送消息 broker 接收不到数据就会数据丢失。**

**ack 等于 1（默认）：意味着 producer 要等待 leader 成功收到数据并得到确认，才发送下一条 message。此选项提供了较好的持久性较低的延迟性。**

**Partition 的 Leader 死亡，follwer 尚未复制，数据就会丢失。**

**ack 等于-1：意味着 producer 得到 follwer 确认，才发送下一条数据**

**持久性最好，延时性最差。**

## Kafka 保证消息的消费顺序

**添加消息时 ，会添加到分区的尾部 故该分区消息是有序的**

**但各个分区的消息不能保证有序（分区一分区 2 的顺序不能确定 不能确定哪个消息早）**

**保证消息有序的方法 **

\*\* \*\*只有一个分区

\*\* \*\*发往指定的分区

\*\* \*\*使用同一个 key（也会发往同一个分区）

## Kafka 如何保证消息不丢失

### 消费者丢失消息

**丢失消息（消息已拉取到 且提交了 offset 但没能成功处理）**

**当消费者拉取到了分区的某个消息之后，消费者会⾃动提交了 offset。⾃动提交的话会有⼀个问**

**题，试想⼀下，当消费者刚拿到这个消息准备进⾏真正消费的时候，突然挂掉了，消息实际上并**

**没有被消费，但是 offset 却被⾃动提交了。**

**解决方案** **：关掉自动提交 offset。但会造成重复消费**

**重复消费 （消息拉取到且消费，但没能提交 offset）**

### 生产者丢失消息

**网络问题。未能发送成功 **

**解决方案** **： retry 注意时间间隔**

### kafka 丢失消息

**leader 副本所在的 broker 挂掉。如果所有人 follwer 副本未与 leader 副本同步完数据。就会造成数据丢失**

**解决方案：acks=all 所有的 follwer 副本接收到数据才算发送成功**

**设置 \*\***replication.factor >= 3\*\* 每个分区有多个副本 虽会造成数据冗余 但带来了数据的安全性

**设置 \*\***min.insync.replicas > 1\*\* 消息至少写入两个副本才算成功发送

**unclean.leader.election.enable = false** **。当 leader 副本发⽣故障时就不会从 follower 副**

**本中和 leader 同步程度达不到要求的副本中选择出 leader ，这样降低了消息丢失的可能性。**

## kafka 如何保证消息不被重复消费

**举个例子，当消费一条消息时就往数据库插入一条数据。如何保证重复消费也插入一条数据呢？**

**　　那么我们就需要从幂等性角度考虑了。幂等性，我通俗点说，就一个数据，或者一个请求，无论来多次，对应的数据都不会改变的，不能出错。**

**怎么保证消息队列消费的幂等性？**

**我们需要结合业务来思考，比如下面的例子：**

**　　 1.比如某个数据要写库，你先根据主键查一下，如果数据有了，就别插入了，update 一下好吧**

**　　 2.比如你是写 redis，那没问题了，反正每次都是 set，天然幂等性**

**　　 3.对于消息，我们可以建个表（专门存储消息消费记录）**

**　　　　生产者，发送消息前判断库中是否有记录（有记录说明已发送），没有记录，先入库，状态为待消费，然后发送消息并把主键 id 带上。**

**　　　　消费者，接收消息，通过主键 ID 查询记录表，判断消息状态是否已消费。若没消费过，则处理消息，处理完后，更新消息记录的状态为已消费。**

[https://www.cnblogs.com/756623607-zhang/p/10506909.html](https://www.cnblogs.com/756623607-zhang/p/10506909.html)

[https://blog.csdn.net/wwwwww33/article/details/105671038](https://blog.csdn.net/wwwwww33/article/details/105671038)

## Kafka 为什么要有分区的概念

[https://www.zhihu.com/question/28925721](https://www.zhihu.com/question/28925721)
