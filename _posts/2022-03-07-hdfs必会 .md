# HDFS

## 基本概念

### NAMENODE

    负责管理文件目录及相关的元数据信息，这些信息以fsimage和editlog两个文件文件形式存在

负责监控 DataNode ，如果某个 DataNode 挂掉，则将该 DataNode 移除 并重新备份数据

### Secondary NameNode

    为NameNode数据热备份

    定期合并fsimage和editlog

### DataNode

    负责实际的数据存储 ，并将数据信息定期汇报给NameNode

    DataNode以block为基本单位存储文件，大文件会切割成若干个block，每次上传文件时一个block一个block的上传

    为保证数据可靠，会将同一个block以流水线的方式写到多个datanode

### block

### packet

### chunk

## Hdfs 的读写流程

    [https://blog.csdn.net/qq_38202756/article/details/82262453]()

### 读

1. client 访问 NameNode，查询元数据信息，获得这个文件的数据块位置列表，返回输入流对象。
2. 就近挑选一台 datanode 服务器，请求建立输入流 。
3. DataNode 向输入流中中写数据，以 packet 为单位来校验。
4. 关闭输入流

### 写

    client端向namenode发送写文件请求 ，namenode检查文件目录 看是否已存在 检查权限

    若通过检查，namenode返回给client目前可写的datanode列表

    client将文件按照block切分，然后将第一个block和datanode列表发送给最近的datanode，稍后此datanode与datanode列表中的其他datanode建立pipeline

    client先发给dn1第一个packet，然后dn1发给dn2,dn2发给dn3

    每个dn写完一个快后就会返回确认信息

写完数据

发送完成信号给 nn

## hdfs 和普通的文件系统有什么不一样，你的意思是它可以无限扩展，为什么不行，后来 hdfs 怎么做的改进

[https://blog.csdn.net/Shockang/article/details/117305825]()

单文件较大

只能在文件尾部追加

局限：namenode 存储有限 不能存储过多的元数据

解决方案：hdfs 联邦 多个 namenode 每个 namenode 负责一部分

## namenode 如果挂掉了怎么办/Hadoop 的高可用

    Hadoop2.0可以配置成HA高可用集群，集群里面有2个namenode节点，一个是active状态，为主节点；另一台是standby状态，为备用节点，两者的数据时刻保持一致。

    当主节点出现问题的时候，备用节点就可以自动切换，用户基本感知不到，这样就避免了namenode的单点问题。

    [https://www.cnblogs.com/drl-blogs/p/11086872.html]()

## 数据块设置成多大合适？

一般设置成 128M,如果设置的太小，一般的文件会被分割成多个数据块，访问的时候就需要查找多个数据块的地址，降低了效率。

如果数据块设置的太小，对 namenode 内存消耗比较严重，因为 namenode 存储了整个集群的数据块信息，内存压力比较大。

如果数据块设置的过大，对于并行的处理就不会太好。也可能会涉及到系统的其他问题，比如系统重启的时候需要重新加载数据，数据块越大，加载的时间就越长。

## hdfs 单点故障

通过主备 NameNode 解决，如果主 NameNode 发生故障，则切换到备 NameNode 主备 namenod

## hdfs 内存受限

HDFS Federation(联邦)hdfs 联 水平扩展，支持多个 NameNode，每个 NameNode 分管一部分目录，所有 NameNode 共享所有 DataNode 存储资源
